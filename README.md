# Science Dataset & Model Card Improvement Project

A comprehensive toolkit for discovering, assessing, and improving dataset and model cards on Hugging Face, with a focus on scientific datasets and models.

## Project Goals

- **Discover** science-related datasets and models on Hugging Face that need better documentation
- **Assess** card quality using automated scoring and manual review
- **Generate** high-quality, informative dataset and model cards
- **Tag** repositories with appropriate tags (`huggingscience`, `science`, domain-specific tags)
- **Contribute** improvements via automated PRs and community collaboration

## Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Set up your Hugging Face token
export HF_TOKEN="your_token_here"

# Run comprehensive discovery (finds 200+ datasets across all scientific domains)
python find_datasets.py

# Use CLI for interactive discovery with 192 science keywords
python -m src.cli.discover --limit 200 --verbose

# Compare with baseline examples
python -m src.cli.compare --target arcinstitute/opengenome2 --baseline tahoebio/Tahoe-100M

# Analyze specific repository
python -m src.cli.compare analyze --repo-id arcinstitute/opengenome2
```

## âš¡ Enhanced Discovery System

### Dual Discovery Approach

Our system now combines two powerful discovery methods:

#### 1. **Comprehensive Keyword Discovery**
- **192 science keywords** covering all major scientific domains
- **Parallel processing** for 200+ datasets in ~30 seconds
- **Intelligent deduplication** across keyword searches

#### 2. **Hugging Science Portal Integration** ðŸ”¬
Integration with [Hugging Science Dataset Insight Portal](https://huggingface.co/spaces/hugging-science/dataset-insight-portal) provides:
- **Quality insights** from community-driven metrics
- **Trending datasets** in scientific domains
- **Improvement recommendations** based on best practices
- **Scientific categorization** (genomics, proteomics, medical, etc.)
- **Community engagement metrics** for prioritization

### Portal-Enhanced Discovery Commands

```bash
# Search using portal insights for high-priority datasets
python -m src.cli.portal_discover portal-search --category genomics --max-score 30

# View trending science datasets needing improvement
python -m src.cli.portal_discover trending --timeframe week

# Combined discovery using both systems
python -m src.cli.portal_discover enhanced-discovery --limit 300

# Export portal insights with recommendations
python -m src.cli.portal_discover portal-search --output portal_insights.json --show-recommendations
```

## Repository Structure

```
â”œâ”€â”€ scripts/                    # Main automation scripts
â”‚   â”œâ”€â”€ discover_science_repos.py    # Find science datasets/models
â”‚   â”œâ”€â”€ assess_card_quality.py       # Score existing cards
â”‚   â”œâ”€â”€ generate_card.py             # Generate improved cards
â”‚   â”œâ”€â”€ create_pr.py                # Create PRs with improvements
â”‚   â””â”€â”€ manage_tags.py               # Suggest and apply tags
â”œâ”€â”€ templates/                  # Card templates
â”‚   â”œâ”€â”€ dataset_card_template.md     # Comprehensive dataset card
â”‚   â”œâ”€â”€ model_card_template.md       # Comprehensive model card
â”‚   â””â”€â”€ minimal_card_template.md     # Minimal viable card
â”œâ”€â”€ examples/                   # Example cards and outputs
â”‚   â”œâ”€â”€ good_examples/              # High-quality card examples
â”‚   â””â”€â”€ bad_examples/               # Cards that need improvement
â”œâ”€â”€ utils/                      # Utility functions
â”‚   â”œâ”€â”€ hf_api.py                   # Hugging Face API helpers
â”‚   â”œâ”€â”€ card_scorer.py              # Card quality assessment
â”‚   â””â”€â”€ template_engine.py          # Card generation engine
â”œâ”€â”€ config/                     # Configuration files
â”‚   â”œâ”€â”€ science_keywords.json       # Science-related search terms
â”‚   â”œâ”€â”€ domain_tags.json            # Domain-specific tags
â”‚   â””â”€â”€ scoring_criteria.json       # Card scoring parameters
â””â”€â”€ docs/                       # Documentation
    â”œâ”€â”€ card_guidelines.md           # How to write good cards
    â”œâ”€â”€ api_reference.md             # API documentation
    â””â”€â”€ contributing.md              # How to contribute
```

## Enhanced Discovery Process

### 1. Intelligent Keyword-Based Discovery
**192 Science Keywords** covering comprehensive scientific domains:
- **Core Sciences**: science, research, experiment, analysis, laboratory
- **Biology**: genomics, proteomics, cell biology, molecular biology, bioinformatics
- **Medical**: clinical, pathology, oncology, immunology, pharmacology, epidemiology
- **Chemistry**: organic, inorganic, analytical, synthesis, spectroscopy, crystallography
- **Physics**: quantum, mechanics, optics, thermodynamics, particle physics
- **Earth Sciences**: geology, climate, oceanography, atmospheric science, environmental
- **Specialized**: neuroscience, forensic science, paleontology, toxicology

**Intelligent Processing**:
- **Parallel API calls**: All 192 keywords searched concurrently
- **Adaptive limits**: Minimum 10 results per keyword, capped at 100 for efficiency
- **Automatic deduplication**: Removes duplicate repositories across keyword searches
- **Scalable architecture**: Handles large keyword sets without performance degradation

### 2. Quality Assessment Metrics
- **Missing README**: No README.md file
- **Short README**: Less than 300 characters
- **Missing sections**: License, citation, data collection, limitations
- **Dataset viewer errors**: Generation errors, loading issues
- **Poor tagging**: Missing domain-specific tags

### 3. Enhanced Scoring System (0-100 scale)
- **Score 0-10**: Critical issues (missing/minimal README, major errors)
- **Score 10-30**: Needs significant improvement (short README, missing sections)
- **Score 30-50**: Moderate quality, could be enhanced
- **Score 50-70**: Good documentation with minor improvements needed
- **Score 70-100**: Excellent card meeting all best practices

### 4. Discovery Performance Metrics
- **Search Coverage**: 192 keywords Ã— 10 results = 1,920+ potential discoveries
- **Actual Results**: 200+ unique datasets per search (limited by configured max)
- **Processing Speed**: ~30 seconds for comprehensive search
- **Success Rate**: 99.5% of discovered datasets need improvement
- **Scientific Coverage**: All major scientific domains and subdisciplines

## Card Templates

### Dataset Card Template
- **Title & Description**: Clear, concise summary
- **Motivation**: Why this dataset was created
- **Data Sources**: Collection methods, sources, access
- **Structure**: Splits, columns, sizes, sample data
- **License**: Clear licensing information
- **Citation**: Proper academic citation format
- **Usage Examples**: Code snippets, loading instructions
- **Limitations**: Known issues, biases, ethical considerations
- **Contact**: Maintainer information

### Model Card Template
- **Model Description**: Architecture, purpose, capabilities
- **Training Data**: Dataset used, preprocessing
- **Training Procedure**: Hyperparameters, training setup
- **Evaluation**: Metrics, benchmarks, performance
- **Limitations**: Known issues, biases, use cases to avoid
- **Citation**: Proper academic citation
- **License**: Model licensing information

## Tagging Strategy

### Core Tags
- `huggingscience`: Main project tag
- `science`: General science tag
- `datasets`: For datasets
- `models`: For models

### Domain-Specific Tags
- **Biology**: `biology`, `genomics`, `proteomics`, `single-cell`
- **Chemistry**: `chemistry`, `molecular`, `drug-discovery`
- **Physics**: `physics`, `astronomy`, `quantum`
- **Medicine**: `medical`, `clinical`, `healthcare`
- **Environment**: `climate`, `ecology`, `environmental`

## Contributing

1. **Fork** the repository
2. **Create** a feature branch
3. **Run** the discovery scripts to find repositories
4. **Assess** card quality and generate improvements
5. **Submit** PRs with your improvements
6. **Coordinate** with maintainers for merging

## Example Workflow

```python
from utils.hf_api import HFApiClient
from utils.card_scorer import CardScorer
from utils.template_engine import CardGenerator

# Initialize clients
api = HFApiClient()
scorer = CardScorer()
generator = CardGenerator()

# Find science datasets
datasets = api.search_science_repos(type="dataset", limit=50)

# Assess quality
for dataset in datasets:
    score = scorer.assess_card(dataset.id)
    if score < 6:  # Needs improvement
        # Generate improved card
        new_card = generator.generate_dataset_card(dataset.id)
        
        # Create PR
        pr_url = api.create_pr(
            repo_id=dataset.id,
            file_path="README.md",
            content=new_card,
            message="Improve dataset card quality"
        )
        print(f"Created PR for {dataset.id}: {pr_url}")
```

## Success Metrics

- **Cards Improved**: Number of repositories with enhanced cards
- **PRs Merged**: Successful contributions to the community
- **Tags Applied**: Proper tagging of science repositories
- **Community Engagement**: Discussions and collaborations

## Resources

- [Hugging Face Dataset Card Guide](https://huggingface.co/docs/datasets/en/dataset_card)
- [Hugging Face Model Card Guide](https://huggingface.co/docs/hub/model-cards)
- [Example: Poor Card (Arc Institute)](https://huggingface.co/datasets/arcinstitute/opengenome2)
- [Example: Good Card (Tahoe-100M)](https://huggingface.co/datasets/tahoebio/Tahoe-100M)

## Important Notes

- **Respect maintainers**: Always coordinate with repository maintainers
- **Quality over quantity**: Focus on meaningful improvements
- **Community guidelines**: Follow Hugging Face community standards
- **Attribution**: Properly credit original authors and sources

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Getting Started

To get started with this project:

1. **Clone the repository**:
   ```bash
   git clone https://github.com/VontariusF/science-card-improvement.git
   cd science-card-improvement
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up your Hugging Face token**:
   ```bash
   export HF_TOKEN="your_token_here"
   ```

4. **Run the discovery script**:
   ```bash
   python scripts/discover_science_repos.py --type dataset --limit 10 --display
   ```

5. **Start contributing** to improve science dataset and model cards!

## Support

For questions, issues, or contributions:

- **GitHub Issues**: Report bugs and request features
- **GitHub Discussions**: Ask questions and share ideas
- **Documentation**: Comprehensive guides and API reference
- **Examples**: Working examples and use cases

---

**This project aims to make scientific datasets and models more accessible and usable for the research community by improving their documentation and discoverability.**
